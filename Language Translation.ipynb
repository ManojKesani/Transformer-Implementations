{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "\n",
    "import torchtext\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from PIL import Image\n",
    "import glob\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LR = 1e-4\n",
    "NUM_EPOCHES = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_english = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_german = spacy.load(\"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_english(text):\n",
    "    return [token.text for token in nlp_english.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_german(text):\n",
    "    return [token.text for token in nlp_german.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'guys', ',', 'my', 'name', 'Jeff']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_english(\"Hi guys, my name Jeff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'dont', 'know', 'any', 'German']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_german(\"I dont know any German\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH = torchtext.data.Field(tokenize=tokenizer_english, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GERMAN = torchtext.data.Field(tokenize=tokenizer_german, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = torchtext.datasets.Multi30k.splits(exts=(\".de\", \".en\"), fields=(GERMAN, ENGLISH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH.build_vocab(train, max_size=10000, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GERMAN.build_vocab(train, max_size=10000, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH vocab_size:  9799\n",
      "GERMAN vocab_size:  10004\n"
     ]
    }
   ],
   "source": [
    "print(\"ENGLISH vocab_size: \", len(ENGLISH.vocab))\n",
    "print(\"GERMAN vocab_size: \", len(GERMAN.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, validation_dataloader, test_dataloader = torchtext.data.BucketIterator.splits(\n",
    "    (train, validation, test),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([16, 64])\n",
      "torch.Size([21, 64])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, data in enumerate(train_dataloader):\n",
    "    print(batch_idx)\n",
    "    print(data.src.size())\n",
    "    print(data.trg.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def german2english(model, german_sentence, device=\"cpu\", max_len=100):\n",
    "    tokens = [token.text.lower() for token in nlp_german(german_sentence)]\n",
    "    tokens = [\"<sos>\"] + tokens + [\"<eos>\"]\n",
    "    \n",
    "    indexes = [GERMAN.vocab.stoi[token] for token in tokens]\n",
    "    indexes_tensor = torch.LongTensor(indexes).unsqueeze(1).to(device)\n",
    "    \n",
    "    english_sentence = [ENGLISH.vocab.stoi[\"<sos>\"]]\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        trg = torch.LongTensor(english_sentence).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            word = model(indexes_tensor, trg)\n",
    "\n",
    "        top = word.argmax(2)[-1, :].item()\n",
    "        english_sentence.append(top)\n",
    "\n",
    "        if top == ENGLISH.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    english_sentence = [ENGLISH.vocab.itos[word] for word in english_sentence]\n",
    "    \n",
    "    return english_sentence[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vocab_size = len(GERMAN.vocab)\n",
    "target_vocab_size = len(ENGLISH.vocab)\n",
    "embed_size = 512\n",
    "num_head = 16\n",
    "num_ff = 1024\n",
    "encoder_layers = 3\n",
    "decoder_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embed): Embedding(10004, 512)\n",
       "  (decoder_embed): Embedding(9799, 512)\n",
       "  (encoder_positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (decoder_positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.2, inplace=False)\n",
       "    (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_layer): TransformerDecoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (multihead_attn): MultiheadAttention(\n",
       "      (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.2, inplace=False)\n",
       "    (dropout2): Dropout(p=0.2, inplace=False)\n",
       "    (dropout3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final): Linear(in_features=512, out_features=9799, bias=True)\n",
       "  (softmax): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer(source_vocab_size, target_vocab_size, embed_size, num_head, num_ff, encoder_layers, decoder_layers, device=device).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimenstions of Input Source Vector:  torch.Size([64, 100])\n",
      "Dimenstions of Input Target Vector:  torch.Size([64, 100])\n",
      "Dimenstions of Predicted Vector:  torch.Size([64, 100, 9799])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Udbhav Prasad\\Documents\\GitHub\\Transformer-Implementation\\models\\transformer.py:192: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "sample_in_x = torch.rand(BATCH_SIZE, 100).type(torch.LongTensor).to(device)\n",
    "sample_in_y = torch.rand(BATCH_SIZE, 100).type(torch.LongTensor).to(device)\n",
    "sample_out = model(sample_in_x, sample_in_y)\n",
    "\n",
    "print(\"Dimenstions of Input Source Vector: \", sample_in_x.size())\n",
    "print(\"Dimenstions of Input Target Vector: \", sample_in_y.size())\n",
    "print(\"Dimenstions of Predicted Vector: \", sample_out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = ENGLISH.vocab.stoi[\"<pad>\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', 'strapped', 'hart', 'jump', 'towarn', 'ec', 'attendees', 'conducted', 'struck', 'purchase', 'inclined', 'tightropes', 'explains', 'pebbly', 'tire', 'plains', 'magnifier', 'marlboro', 'kicks', 'graduate', 'gift', 'dior', 'flashlight', 'beige', 'sponge', 'down', 'amazing', 'role', 'diego', 'supporters', 'cheerleaders', 'marina', 'attacked', 'stuck', 'juggles', 'of', 'redhead', 'walkways', 'sang', 'distributing', 'gesture', 'karaoke', 'flood', 'tapestry', 'swetashirts', 'sodas', 'kilometers', 'pier', 'uw', 'gog', 'assortment', '3rd', 'snowflakes', 'portraits', 'applause', 'ranching', 'pod', 'brownish', 'ring', 'mouthing', 'chases', 'skateboards', 'dumpster', 'safely', 'welds', 'falling', 'wildly', 'glacier', 'packers', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 1 Train mean loss: 0.13872378\n",
      "       1 Test  mean loss: 0.13828865\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 2 Train mean loss: 0.13699639\n",
      "       2 Test  mean loss: 0.13766432\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 3 Train mean loss: 0.13650431\n",
      "       3 Test  mean loss: 0.13720432\n",
      "-------------------------------------------------\n",
      "['<unk>', 'on', 'his', 'bike', 'and', 'white', 'dog', 'is', 'walking', 'on', 'the', 'sidewalk', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 4 Train mean loss: 0.13620121\n",
      "       4 Test  mean loss: 0.13691560\n",
      "-------------------------------------------------\n",
      "['<unk>', 'of', 'them', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 5 Train mean loss: 0.13597699\n",
      "       5 Test  mean loss: 0.13675045\n",
      "-------------------------------------------------\n",
      "['<unk>', 'player', 'is', 'standing', 'on', 'his', 'hands', 'while', 'another', 'man', 'wearing', 'glasses', 'is', 'photographed', '-', 'shirt', 'and', 'white', 't', '-', 'shirt', 'and', 'white', 'pants', 'are', 'sitting', 'at', 'night', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 6 Train mean loss: 0.13580467\n",
      "       6 Test  mean loss: 0.13657287\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 7 Train mean loss: 0.13565150\n",
      "       7 Test  mean loss: 0.13646594\n",
      "-------------------------------------------------\n",
      "['<unk>', '-', 'shirt', 'and', 'khaki', 'his', 'cellphone', 'to', 'take', 'pictures', 'of', 'paper', 'on', 'stage', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 8 Train mean loss: 0.13541837\n",
      "       8 Test  mean loss: 0.13624745\n",
      "-------------------------------------------------\n",
      "['<unk>', 'player', 'is', 'holding', 'up', 'to', 'take', 'pictures', 'shirt', 'is', 'leading', 'color', 'skirt', 'are', 'gathered', 'on', 'stage', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 9 Train mean loss: 0.13526780\n",
      "       9 Test  mean loss: 0.13616761\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 10 Train mean loss: 0.13513060\n",
      "       10 Test  mean loss: 0.13605810\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 11 Train mean loss: 0.13502093\n",
      "       11 Test  mean loss: 0.13600593\n",
      "-------------------------------------------------\n",
      "['<unk>', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 12 Train mean loss: 0.13492093\n",
      "       12 Test  mean loss: 0.13592794\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 13 Train mean loss: 0.13481152\n",
      "       13 Test  mean loss: 0.13586536\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 14 Train mean loss: 0.13473402\n",
      "       14 Test  mean loss: 0.13585150\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 15 Train mean loss: 0.13463736\n",
      "       15 Test  mean loss: 0.13579206\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 16 Train mean loss: 0.13457851\n",
      "       16 Test  mean loss: 0.13575110\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 17 Train mean loss: 0.13449353\n",
      "       17 Test  mean loss: 0.13571324\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 18 Train mean loss: 0.13442751\n",
      "       18 Test  mean loss: 0.13567492\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 19 Train mean loss: 0.13436616\n",
      "       19 Test  mean loss: 0.13564175\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 20 Train mean loss: 0.13429696\n",
      "       20 Test  mean loss: 0.13562625\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 21 Train mean loss: 0.13422133\n",
      "       21 Test  mean loss: 0.13555830\n",
      "-------------------------------------------------\n",
      "['<unk>', 'while', 'sitting', 'in', 'its', 'hind', 'are', 'playing', 'with', 'dreadlocks', 'of', 'paper', 'as', 'it', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 22 Train mean loss: 0.13417136\n",
      "       22 Test  mean loss: 0.13555950\n",
      "-------------------------------------------------\n",
      "['<unk>', 'while', 'standing', 'in', 'red', 'collar', 'neck', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 23 Train mean loss: 0.13411875\n",
      "       23 Test  mean loss: 0.13552109\n",
      "-------------------------------------------------\n",
      "['<unk>', 'while', 'sitting', 'in', 'its', 'hind', 'are', 'playing', 'with', 'dreadlocks', 'building', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 24 Train mean loss: 0.13406234\n",
      "       24 Test  mean loss: 0.13550778\n",
      "-------------------------------------------------\n",
      "['<unk>', 'while', 'sitting', 'in', 'its', 'hind', 'are', 'playing', 'with', 'dreadlocks', 'of', 'paper', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 25 Train mean loss: 0.13399601\n",
      "       25 Test  mean loss: 0.13550390\n",
      "-------------------------------------------------\n",
      "['<unk>', 'while', 'wearing', 'white', 't', '-', 'fives', 'into', 'the', 'street', 'performer', 'with', 'a', 'red', 'collar', 'snowboards', 'on', 'stage', 'full', 'of', 'them', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 26 Train mean loss: 0.13395554\n",
      "       26 Test  mean loss: 0.13547530\n",
      "-------------------------------------------------\n",
      "['<unk>', 'while', 'wearing', 'white', 'dog', 'is', 'airborne', 'and', 'groom', 'and', 'adult', 'supervision', 'something', 'from', 'the', 'street', 'where', 'instruments', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 27 Train mean loss: 0.13389760\n",
      "       27 Test  mean loss: 0.13542922\n",
      "-------------------------------------------------\n",
      "['<unk>', 'while', 'wearing', 'blue', 't', '-', 'hair', 'is', 'about', 'to', 'reach', 'something', 'in', 'its', 'mouth', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 28 Train mean loss: 0.13384815\n",
      "       28 Test  mean loss: 0.13540367\n",
      "-------------------------------------------------\n",
      "['<unk>', 'while', 'sitting', 'in', 'the', 'street', 'performer', 'is', 'running', 'up', 'to', 'fix', 'something', 'from', 'the', 'little', 'girl', \"'s\", 'shoulder', 'of', 'metal', 'structure', ',', 'while', 'another', 'man', 'takes', 'place', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 29 Train mean loss: 0.13379770\n",
      "       29 Test  mean loss: 0.13541078\n",
      "-------------------------------------------------\n",
      "['<unk>', 'gear', 'and', 'white', 'dog', 'in', 'red', 'collar', 'clothes', 'jumping', 'up', 'against', 'each', 'other', 'people', 'protesting', 'something', 'on', 'stage', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 30 Train mean loss: 0.13376701\n",
      "       30 Test  mean loss: 0.13536655\n",
      "-------------------------------------------------\n",
      "['<unk>', 'while', 'sitting', 'in', 'the', 'street', 'with', 'their', 'hands', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 31 Train mean loss: 0.13370354\n",
      "       31 Test  mean loss: 0.13536902\n",
      "-------------------------------------------------\n",
      "['<unk>', 'while', 'sitting', 'in', 'asia', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 32 Train mean loss: 0.13366731\n",
      "       32 Test  mean loss: 0.13535647\n",
      "-------------------------------------------------\n",
      "['<unk>', 'area', 'with', 'her', 'dog', 'jumps', 'over', 'her', 'guitar', 'in', 'midair', 'on', 'stage', 'with', 'two', 'men', 'sit', 'cross', 'legged', 'tunnel', 'in', 'red', 'collar', 'is', 'running', 'past', 'volcano', 'eruptions', 'worker', 'wearing', 'blue', 'jeans', 'is', 'airborne', 'stand', 'in', 'mud', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 33 Train mean loss: 0.13362040\n",
      "       33 Test  mean loss: 0.13530800\n",
      "-------------------------------------------------\n",
      "['<unk>', 'area', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 34 Train mean loss: 0.13357779\n",
      "       34 Test  mean loss: 0.13530994\n",
      "-------------------------------------------------\n",
      "['<unk>', 'area', 'with', 'his', 'hand', '-', 'shirt', 'is', 'riding', 'his', 'work', 'on', 'the', 'street', 'performer', 'wearing', 'sunglasses', 'sit', 'behind', 'him', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 35 Train mean loss: 0.13354141\n",
      "       35 Test  mean loss: 0.13532998\n",
      "-------------------------------------------------\n",
      "['<unk>', 'area', 'with', 'graffiti', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 36 Train mean loss: 0.13351962\n",
      "       36 Test  mean loss: 0.13531804\n",
      "-------------------------------------------------\n",
      "['<unk>', 'area', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 37 Train mean loss: 0.13344652\n",
      "       37 Test  mean loss: 0.13529615\n",
      "-------------------------------------------------\n",
      "['<unk>', 'area', 'with', 'his', 'bicycle', 'across', 'the', 'street', 'performer', 'dressed', 'in', 'asia', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 38 Train mean loss: 0.13340936\n",
      "       38 Test  mean loss: 0.13528105\n",
      "-------------------------------------------------\n",
      "['<unk>', 'area', 'with', 'his', 'bicycle', 'across', 'the', 'street', 'performer', 'is', 'standing', 'next', 'to', 'fix', 'something', 'from', 'scoring', 'building', 'with', 'three', 'people', 'gather', 'for', 'tips', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 39 Train mean loss: 0.13338541\n",
      "       39 Test  mean loss: 0.13526658\n",
      "-------------------------------------------------\n",
      "['<unk>', 'area', 'with', 'his', 'bicycle', 'rental', 'shirt', 'is', 'riding', 'his', 'balance', 'beam', 'watches', 'tv', 'screens', 'wearing', 'sunglasses', 'and', 'sandals', 'is', 'falling', 'off', 'the', 'street', 'performer', 'dressed', 'in', 'front', 'of', 'luck', 'pole', 'vaulter', 'athlete', 'who', 'are', 'sitting', 'outside', 'float', 'or', 'trolley', 'suit', 'bald', 'bubbles', 'over', 'the', 'counter', 'filled', 'with', 'many', 'people', 'gather', 'before', 'racks', 'shirts', 'and', 'tan', 'jacket', 'practices', 'something', 'from', 'the', 'kicker', 'attempts', 'to', 'fix', 'benches', 'buildings', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 40 Train mean loss: 0.13335075\n",
      "       40 Test  mean loss: 0.13526790\n",
      "-------------------------------------------------\n",
      "['<unk>', 'while', 'wearing', 'blue', 't', '-', 'hair', 'is', 'jumping', 'in', 'the', 'street', 'performer', 'with', 'blond', 'throw', 'something', 'that', 'says', '\"', 'welcome', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 41 Train mean loss: 0.13332550\n",
      "       41 Test  mean loss: 0.13523276\n",
      "-------------------------------------------------\n",
      "['<unk>', 'while', 'wearing', 'blue', 'shirt', 'is', 'jumping', 'in', 'its', 'mouth', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 42 Train mean loss: 0.13326638\n",
      "       42 Test  mean loss: 0.13521155\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 43 Train mean loss: 0.13323470\n",
      "       43 Test  mean loss: 0.13521313\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 44 Train mean loss: 0.13320752\n",
      "       44 Test  mean loss: 0.13520623\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 45 Train mean loss: 0.13318299\n",
      "       45 Test  mean loss: 0.13522479\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', 'from', 'his', 'bicycle', 'rental', 'uniform', 'is', 'riding', 'his', 'might', 'be', 'reacting', 'to', 'fix', 'wood', 'chipper', 'of', 'paper', 'plate', 'of', 'bystanders', 'in', 'jeans', 'she', 'walks', 'by', 'another', 'person', 'wearing', 'sunglasses', 'reclines', 'around', 'him', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 46 Train mean loss: 0.13314268\n",
      "       46 Test  mean loss: 0.13517620\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', 'from', 'the', 'street', 'performer', 'is', 'standing', 'in', 'red', 'umbrella', 'simply', 'down', 'from', 'their', 'hands', 'raised', 'platform', 'as', 'two', 'women', 'who', 'is', 'focused', 'straight', 'ahead', 'of', 'paper', 'plate', 'snowmen', 'on', 'stage', 'with', 'dreadlocks', 'sits', 'cross', 'legged', 'game', 'starts', 'to', 'fix', 'something', 'off', 'excess', 'salmon', 'colored', 'mercury', 'completing', 'repairs', 'through', 'lush', 'tunnel', 'while', 'balancing', 'high', 'heels', 'hugs', '\"', 'sine', 'area', 'that', 'reads', 'teaching', 'math', 'to', 'kiss', 'screen', 'appearing', 'to', 'use', 'cables', 'bottle', 'fell', 'asleep', 'down', 'for', 'tips', 'square', 'and', 'tan', 'pants', 'stands', 'near', 'a', 'microphone', 'held', 'up', 'against', 'those', 'places', 'her', 'stomach', 'mask', 'works', 'properly', 'married', 'ethnic', 'foods', 'leans', 'over']\n",
      "-------------------------------------------------\n",
      "Epoch: 47 Train mean loss: 0.13312854\n",
      "       47 Test  mean loss: 0.13515781\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', 'from', 'the', 'sidewalk', ',', 'both', 'sides', 'uniform', ',', 'is', 'playing', 'tug', 'sports', 'jerseys', 'sit', 'at', 'dusk', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 48 Train mean loss: 0.13307874\n",
      "       48 Test  mean loss: 0.13514780\n",
      "-------------------------------------------------\n",
      "['<unk>', 'area', 'with', 'their', 'hands', 'raised', 'in', 'the', 'street', 'performer', 'sitting', 'in', 'its', 'wings', 'walk', 'by', 'trees', 'showing', 'her', 'stomach', 'dress', 'is', 'sitting', 'inside', 'of', 'paper', 'plate', 'of', 'food', 'buffet', 'made', 'wheel', 'barrel', 'rides', 'his', 'skateboard', 'enthusiast', 'walkway', ',', 'possibly', 'debating', 'mountain', 'biker', 'scouts', 'watches', 'tv', 'screens', 'balding', 'hanging', 'out', 'brochures', 'building', 'where', 'flowers', 'pulled', 'up', 'debris', 'colored', 't', '-', 'fashioned', 'ice', 'cream', 'cone', 'area', 'writing', 'something', 'on', 'the', 'military', 'personnel', 'learning', 'how', 'to', 'fix', 'two', 'women', 'who', 'is', 'airborne', 'fence', 'filled', 'with', 'chopsticks', 'for', 'sale', 'sticking', 'straight', 'ahead', 'of', 'an', 'old', 'man', 'wears', 'silly', 'faces', 'painted', 'targets', 'diving', 'board']\n",
      "-------------------------------------------------\n",
      "Epoch: 49 Train mean loss: 0.13304136\n",
      "       49 Test  mean loss: 0.13515114\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 50 Train mean loss: 0.13303089\n",
      "       50 Test  mean loss: 0.13513802\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', 'from', 'his', 'bicycle', 'rental', 'cloth', 'high', 'in', 'formal', 'attire', 'standing', 'outside', 'of', 'water', 'slide', 'on', 'stage', 'with', 'dreadlocks', 'part', 'suit', 'smiles', 'as', 'they', 'walk', 'through', 'lush', \"'s\", 'sleigh', 'directions', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 51 Train mean loss: 0.13299104\n",
      "       51 Test  mean loss: 0.13515914\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', 'from', 'his', 'bicycle', 'rental', 'uniform', 'is', 'playing', 'tug', '-', 'skinned', 'rollerblades', 'store', 'called', 'cap', 'walks', 'down', 'from', 'the', 'street', 'performer', 'in', 'jeans', 'are', 'sitting', 'down', 'signing', 'pigeons', 'fly', 'around', 'her', 'ipod', 'high', 'rate', 'they', 'walk', 'by', 'trees', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 52 Train mean loss: 0.13296899\n",
      "       52 Test  mean loss: 0.13514926\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', 'from', 'his', 'bicycle', 'rental', 'uniform', 'is', 'playing', 'monopoly', 'on', 'stage', ',', 'possibly', 'debating', 'tree', 'branch', 'off', 'of', 'water', 'pipes', 'flexing', 'coat', 'and', 'sandals', 'is', 'positioned', 'outside', 'near', 'a', 'black', 'pants', ',', 'one', 'man', 'in', 'front', 'of', 'canadian', 'flags', 'displayed', 'down', 'from', 'opposite', 'directions', 'around', 'her', 'ipod', 'nearby', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 53 Train mean loss: 0.13293368\n",
      "       53 Test  mean loss: 0.13513628\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', 'is', 'holding', 'umbrellas', 'shop', 'on', 'his', 'bicycle', 'across', 'water', 'slide', 'into', 'microphones', 'in', 'purple', 'shirt', 'is', 'nibbling', 'photographs', 'expression', '-', 'fashioned', 'bag', 'snowboards', 'out', 'brochures', 'doors', 'chair', 'with', 'dreadlocks', 'are', 'sitting', 'in', 'black', 'pants', 'is', 'shaving', 'cream', 'cone', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 54 Train mean loss: 0.13289254\n",
      "       54 Test  mean loss: 0.13512460\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', 'is', 'holding', 'her', 'hand', 'outstretched', 'building', 'passes', 'by', 'another', 'person', 'is', 'walking', 'along', 'the', 'street', 'corner', 'gymnastics', 'toy', 'airplane', 'flies', 'low', 'cut', 'rolled', 'up', 'against', 'the', 'young', 'boy', 'scout', 'dress', 'are', 'sitting', 'next', 'to', 'fix', 'their', 'mouths', 'open', 'toed', 'pipe', 'tied', 'jeans', 'is', 'drinking', 'canned', 'soft', 'figure', 'jumps', 'over', 'possession', 'punts', 'striped', 'shirt', 'and', 'sandals', 'sits', 'among', 'piles', 'attempt', 'for', 'sale', 'filled', 'with', 'dreadlocks', ',', 'possibly', 'debating', 'tree', 'stump', 'overlooking', 'gardens', 'jacket', 'and', 'pointing', 'upward', 'apart', 'because', 'turns', 'around', 'them', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 55 Train mean loss: 0.13286954\n",
      "       55 Test  mean loss: 0.13514679\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', 'from', 'his', 'bicycle', 'rental', 'shirt', 'is', 'standing', 'outside', 'of', 'water', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 56 Train mean loss: 0.13285706\n",
      "       56 Test  mean loss: 0.13510114\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', 'another', 'individual', 'pushing', 'his', 'bicycle', 'across', 'the', 'street', 'performers', 'sing', 'joyous', 'inflatable', 'rafts', 'and', 'sandals', 'is', 'playing', 'with', 'dreadlocks', 'colors', 'stand', 'outside', 'of', 'paper', 'plate', 'snowmen', 'place', 'for', 'sale', 'runner', 'wearing', 'black', 'pants', 'pulled', 'down', 'from', 'behind', 'him', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 57 Train mean loss: 0.13281401\n",
      "       57 Test  mean loss: 0.13512863\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', 'another', 'individual', 'pushing', 'his', 'bicycle', 'across', 'the', 'street', 'festival', 'building', \"'s\", 'tail', 'raised', 'platform', 'as', 'they', 'walk', 'by', 'channel', '1', 'hour', 'goods', 'before', 'racks', 'of', 'metal', 'ladle', 'costume', 'stands', 'near', 'a', 'young', 'asian', 'man', 'wearing', 'only', 'both', 'sides', 'of', 'paper', 'plate', 'snowmen', 'items', 'on', 'either', 'warming', 'something', 'into', 'winded', 'endurance', 'test', 'tube', 'full', 'of', 'golf', 'ball', 'pit', 'crew', 'documents', 'team', 'who', 'is', 'drinking', 'straight', 'ahead', 'of', 'water', 'droplets', 'store', 'clerk', 'setting', 'up', 'against', 'crowds', 'eastern', 'heritage', 'pulled', 'through', 'lush', 'tunnel', 'while', 'seated', 'at', 'dusk', 'attendant', 'approaches', 'barbecue', 'chicken', 'above', 'them', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 58 Train mean loss: 0.13279206\n",
      "       58 Test  mean loss: 0.13508986\n",
      "-------------------------------------------------\n",
      "['<unk>', 'while', 'wearing', 'blue', 'jacket', 'is', 'jumping', 'in', 'front', 'of', 'her', 'hands', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 59 Train mean loss: 0.13275565\n",
      "       59 Test  mean loss: 0.13509978\n",
      "-------------------------------------------------\n",
      "['<unk>', 'area', 'with', 'his', 'hand', 'outstretched', 'communicates', 'walking', 'along', 'the', 'street', 'performer', 'is', 'running', 'very', 'long', 'maroon', 'jerseys', 'sit', 'behind', 'him', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 60 Train mean loss: 0.13275204\n",
      "       60 Test  mean loss: 0.13511272\n",
      "-------------------------------------------------\n",
      "['<unk>', 'with', 'his', 'hair', 'is', 'wearing', 'blue', 'shirt', 'is', 'at', 'him', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 61 Train mean loss: 0.13271556\n",
      "       61 Test  mean loss: 0.13508355\n",
      "-------------------------------------------------\n",
      "['<unk>', 'with', 'his', 'hand', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 62 Train mean loss: 0.13268332\n",
      "       62 Test  mean loss: 0.13511624\n",
      "-------------------------------------------------\n",
      "['<unk>', 'with', 'his', 'hand', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 63 Train mean loss: 0.13266374\n",
      "       63 Test  mean loss: 0.13502767\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 64 Train mean loss: 0.13264454\n",
      "       64 Test  mean loss: 0.13503005\n",
      "-------------------------------------------------\n",
      "['<unk>', 'day', 'from', 'his', 'hand', 'outstretched', 'communicates', 'ready', 'to', 'eat', 'ice', 'cream', 'cone', 'in', 'asia', 'polo', 'shirt', 'is', 'holding', 'onto', 'her', 'phone', 'in', 'its', 'finale', 'attached', 'ditch', 'worker', 'wearing', 'black', 'pants', 'is', 'holding', 'onto', 'the', 'street', 'performer', 'dressed', 'in', 'dirty', '4', 'people', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 65 Train mean loss: 0.13263232\n",
      "       65 Test  mean loss: 0.13503251\n",
      "-------------------------------------------------\n",
      "['<unk>', 'with', 'two', 'people', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 66 Train mean loss: 0.13261473\n",
      "       66 Test  mean loss: 0.13506275\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 67 Train mean loss: 0.13255714\n",
      "       67 Test  mean loss: 0.13504896\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 68 Train mean loss: 0.13254244\n",
      "       68 Test  mean loss: 0.13505976\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 69 Train mean loss: 0.13251446\n",
      "       69 Test  mean loss: 0.13501452\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 70 Train mean loss: 0.13250483\n",
      "       70 Test  mean loss: 0.13504187\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 71 Train mean loss: 0.13247806\n",
      "       71 Test  mean loss: 0.13504244\n",
      "-------------------------------------------------\n",
      "['<unk>', 'something', 'in', 'the', 'woman', 'are', 'sitting', 'at', 'dusk', 'and', 'drinking', 'wine', 'bottles', 'for', 'sale', 'floating', 'up', 'debris', 'on', 'the', 'man', 'is', 'being', 'watched', 'face', 'paint', 'can', 'be', 'unexcited', 'cut', 'colored', 't', '-', 'dot', 'flowers', 'talks', 'on', 'stage', 'with', 'dreadlocks', 'is', 'holding', 'up', 'against', 'those', 'places', 'his', 'cellphone', 'while', 'they', 'walk', 'past', 'volcano', 'eruptions', 'worker', 'actively', 'engaged', 'in', 'front', 'of', 'them', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 72 Train mean loss: 0.13244721\n",
      "       72 Test  mean loss: 0.13503387\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 73 Train mean loss: 0.13243117\n",
      "       73 Test  mean loss: 0.13498098\n",
      "-------------------------------------------------\n",
      "['<unk>', 'area', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 74 Train mean loss: 0.13239399\n",
      "       74 Test  mean loss: 0.13500652\n",
      "-------------------------------------------------\n",
      "['<unk>', 'on', 'the', 'water', 'bottle', 'of', 'metal', 'tub', 'pride', 'wedding', 'cake', 'to', 'fix', 'her', 'cellphone', 'outside', 'papa', '-', 'haired', 'man', 'is', 'running', 'along', 'side', '!', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 75 Train mean loss: 0.13236914\n",
      "       75 Test  mean loss: 0.13495863\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 76 Train mean loss: 0.13235369\n",
      "       76 Test  mean loss: 0.13501383\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 77 Train mean loss: 0.13233071\n",
      "       77 Test  mean loss: 0.13498116\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 78 Train mean loss: 0.13232500\n",
      "       78 Test  mean loss: 0.13497380\n",
      "-------------------------------------------------\n",
      "['<unk>', 'on', 'his', 'hand', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 79 Train mean loss: 0.13229337\n",
      "       79 Test  mean loss: 0.13498637\n",
      "-------------------------------------------------\n",
      "['<unk>', 'with', 'two', 'people', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 80 Train mean loss: 0.13227126\n",
      "       80 Test  mean loss: 0.13496426\n",
      "-------------------------------------------------\n",
      "['<unk>', 'on', 'the', 'red', '-', 'hair', 'is', 'sitting', 'on', 'his', 'hands', 'raised', 'platform', 'with', 'black', 'leather', 'jacket', 'looks', 'on', 'him', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 81 Train mean loss: 0.13225175\n",
      "       81 Test  mean loss: 0.13498092\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 82 Train mean loss: 0.13223963\n",
      "       82 Test  mean loss: 0.13497696\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 83 Train mean loss: 0.13221871\n",
      "       83 Test  mean loss: 0.13495387\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 84 Train mean loss: 0.13221573\n",
      "       84 Test  mean loss: 0.13498906\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 85 Train mean loss: 0.13217535\n",
      "       85 Test  mean loss: 0.13492501\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 86 Train mean loss: 0.13215486\n",
      "       86 Test  mean loss: 0.13494553\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 87 Train mean loss: 0.13214922\n",
      "       87 Test  mean loss: 0.13495210\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 88 Train mean loss: 0.13212694\n",
      "       88 Test  mean loss: 0.13493888\n",
      "-------------------------------------------------\n",
      "['<unk>', '-', 'shirt', 'is', 'holding', 'two', 'people', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 89 Train mean loss: 0.13210280\n",
      "       89 Test  mean loss: 0.13491919\n",
      "-------------------------------------------------\n",
      "['<unk>', 'with', 'two', 'men', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 90 Train mean loss: 0.13208684\n",
      "       90 Test  mean loss: 0.13491362\n",
      "-------------------------------------------------\n",
      "['<unk>', 'with', 'two', 'men', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 91 Train mean loss: 0.13208963\n",
      "       91 Test  mean loss: 0.13493318\n",
      "-------------------------------------------------\n",
      "['<unk>', 'on', 'the', 'woman', 'are', 'sitting', 'on', 'his', 'bicycle', 'loaded', 'with', 'no', 'shirt', 'is', 'holding', 'two', 'people', 'are', 'walking', 'for', 'sale', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 92 Train mean loss: 0.13205872\n",
      "       92 Test  mean loss: 0.13491613\n",
      "-------------------------------------------------\n",
      "['<unk>', 'on', 'the', 'man', 'is', 'in', 'dirty', 'umbrella', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 93 Train mean loss: 0.13203896\n",
      "       93 Test  mean loss: 0.13488657\n",
      "-------------------------------------------------\n",
      "['<unk>', 'with', 'two', 'men', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 94 Train mean loss: 0.13204191\n",
      "       94 Test  mean loss: 0.13489333\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 95 Train mean loss: 0.13201718\n",
      "       95 Test  mean loss: 0.13490985\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 96 Train mean loss: 0.13200139\n",
      "       96 Test  mean loss: 0.13489390\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 97 Train mean loss: 0.13196908\n",
      "       97 Test  mean loss: 0.13489881\n",
      "-------------------------------------------------\n",
      "['<unk>', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 98 Train mean loss: 0.13196254\n",
      "       98 Test  mean loss: 0.13490428\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 99 Train mean loss: 0.13196445\n",
      "       99 Test  mean loss: 0.13487534\n",
      "-------------------------------------------------\n",
      "['<unk>', '.', '<eos>']\n",
      "-------------------------------------------------\n",
      "Epoch: 100 Train mean loss: 0.13192626\n",
      "       100 Test  mean loss: 0.13486867\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHES+1):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    print(german2english(model, \"Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\", device=device)) # A man in an orange hat starring at something.\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_train_loss = 0\n",
    "    epoch_test_loss = 0  \n",
    "    \n",
    "    for batch_idx, data in enumerate(train_dataloader):\n",
    "        x = data.src.to(device)\n",
    "        y = data.trg.to(device)\n",
    "        \n",
    "        y_pred = model(x, y[:-1, :])\n",
    "        \n",
    "        #print(y_pred.size())\n",
    "        #print(y.size())\n",
    "        \n",
    "        y_pred = y_pred.reshape(-1, y_pred.size(2))\n",
    "        y = y[1:].reshape(-1)\n",
    "        \n",
    "        #print(y_pred.size())\n",
    "        #print(y.size())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        for batch_idx, data in enumerate(validation_dataloader):\n",
    "            x = data.src.to(device)\n",
    "            y = data.trg.to(device)\n",
    "        \n",
    "            y_pred = model(x, y[:-1, :])\n",
    "            y_pred = y_pred.reshape(-1, y_pred.size(-1))\n",
    "            y = y[1:, :].reshape(-1)\n",
    "        \n",
    "            loss = criterion(y_pred, y)\n",
    "        \n",
    "            epoch_test_loss += loss.item()\n",
    "    \n",
    "    epoch_train_loss = epoch_train_loss / len(train_dataloader.dataset)\n",
    "    epoch_test_loss = epoch_test_loss / len(validation_dataloader.dataset)\n",
    "    \n",
    "    scheduler.step(epoch_train_loss)\n",
    "    \n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"Epoch: {} Train mean loss: {:.8f}\".format(epoch, epoch_train_loss))\n",
    "    print(\"       {} Test  mean loss: {:.8f}\".format(epoch, epoch_test_loss))\n",
    "    print(\"-------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '.', '<eos>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german2english(model, \"Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\", device=device) # A man in an orange hat starring at something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"trained_models/language_translation_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}